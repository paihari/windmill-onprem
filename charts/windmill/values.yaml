postgresql:
  # -- enabled included Postgres container for demo purposes only using bitnami
  enabled: true
  fullnameOverride: windmill-postgresql
  primary:
    persistence:
      enabled: true
  auth:
    postgresPassword: windmill
    database: windmill

minio:
  # -- enabled included Minio operator for s3 resource demo purposes
  enabled: false
  fullnameOverride: windmill-minio
  mode: standalone
  primary:
    enabled: true
  auth:
    rootUser: windmill
    rootPassword: windmill

windmill:
  # -- windmill app image tag, will use the App version if not defined
  tag: ""
  # -- replica for the application app
  appReplicas: 2
  # -- replicas for the workers, jobs are executed on the workers
  workerReplicas: 2
  # -- replicas for the lsp containers used by the app
  lspReplicas: 2
  # -- replicas for the lsp containers used by the app
  multiplayerReplicas: 2
  # -- name of the secret storing the database URI, take precedence over databaseUrl. The key of the url is 'url'
  databaseUrlSecretName: ""
  # -- Postgres URI, pods will crashloop if database is unreachable, sets DATABASE_URL environment variable in app and worker container
  databaseUrl: postgres://postgres:windmill@windmill-postgresql/windmill?sslmode=disable
  # -- domain as shown in browser, this variable and `baseProtocol` are used as part of the BASE_URL environment variable in app and worker container and in the ingress resource, if enabled
  baseDomain: bantwal.ch
  # -- protocol as shown in browser, change to https etc based on your endpoint/ingress configuration, this variable and `baseDomain` are used as part of the BASE_URL environment variable in app and worker container
  baseProtocol: http
  # -- domain to use for the cookies. Use it if windmill is hosted on a subdomain and you need to share the cookies with the hub for instance
  cookieDomain: ""
  # -- rust log level, set to debug for more information etc, sets RUST_LOG environment variable in app and worker container
  rustLog: info
  # -- workers per worker container, default and recommended is 1 to isolate one process per container, sets NUM_WORKER environment variable for worker container.  app container has 0 NUM_WORKERS by default
  numWorkers: 1
  # -- name of the secret storing the oauthConfig. See https://docs.windmill.dev/docs/misc/setup_oauth
  oauthSecretName: ""
  # -- raw oauth config. See https://docs.windmill.dev/docs/misc/setup_oauth
  oauthConfig: |
    {}
  # -- pass the index url to pip for private registries
  pipIndexUrl: ""
  # -- pass the extra index url to pip for private registries
  pipExtraIndexUrl: ""
  # -- pass the trusted host to pip for private registries
  pipTrustedHost: ""
  # -- pass the npm for private registries
  npmConfigRegistry: ""
  # -- send instance events to a webhook. Can be hooked back to windmill
  instanceEventsWebhook: ""
  # -- mount the docker socket inside the container to be able to run docker command as docker client to the host docker daemon
  exposeHostDocker: false
  # -- if set, the path to a script in the admins workspace that will be triggered upon any jobs failure
  globalErrorHandlerPath: ""
  # -- is any user allowed to create workspaces
  createWorkspaceRequireSuperadmin: false
  # -- set smtp configs for windmill to be able to send emails when adding users to instance and workspaces
  smtp:
    enabled: false
    host: smtp.gmail.com
    port: 587
    from: noreply@windmill.dev
    username: ruben@windmill.dev
    password: bar
    tls_implicit: false

  # extra worker groups
  workerGroups:
    # workers configuration
    - name: "gpu"
      replicas: 0
      # -- Annotations to apply to the pods
      annotations: {}

      # -- Node selector to use for scheduling the pods
      nodeSelector: {}

      # -- Tolerations to apply to the pods
      tolerations: []

      # -- Affinity rules to apply to the pods
      affinity: {}

      # -- Resource limits and requests for the pods
      resources: {}

      # -- Extra environment variables to apply to the pods
      extraEnv: []

  # workers configuration
  workers:
    # -- Annotations to apply to the pods
    annotations: {}

    # -- Node selector to use for scheduling the pods
    nodeSelector: {}

    # -- Tolerations to apply to the pods
    tolerations: []

    # -- Affinity rules to apply to the pods
    affinity: {}

    # -- Resource limits and requests for the pods
    resources: {}

    # -- Extra environment variables to apply to the pods
    extraEnv: []

    # workers autoscaling configuration
    autoscaling:
      # -- enable or disable autoscaling
      # -- autoscaling is not recommended without using the enterprise edition since workers
      # -- will not benefit from the global cache and the performances will be poor for newly spawned pods
      enabled: false
      # -- maximum autoscaler replicas
      maxReplicas: 10
      # -- target CPU utilization
      targetCPUUtilizationPercentage: 80

  # app configuration
  app:
    # -- Annotations to apply to the pods
    annotations: {}

    # -- Node selector to use for scheduling the pods
    nodeSelector: {}

    # -- Tolerations to apply to the pods
    tolerations: []

    # -- Affinity rules to apply to the pods
    affinity: {}

    # -- Resource limits and requests for the pods
    resources: {}

    # -- Extra environment variables to apply to the pods
    extraEnv: []

    # app autoscaling configuration
    autoscaling:
      # -- enable or disable autoscaling
      enabled: false
      # -- maximum autoscaler replicas
      maxReplicas: 10
      # -- target CPU utilization
      targetCPUUtilizationPercentage: 80

  # lsp configuration
  lsp:
    tag: "latest"
    # -- Annotations to apply to the pods
    annotations: {}

    # -- Node selector to use for scheduling the pods
    nodeSelector: {}

    # -- Tolerations to apply to the pods
    tolerations: []

    # -- Affinity rules to apply to the pods
    affinity: {}

    # -- Resource limits and requests for the pods
    resources: {}

    # -- Extra environment variables to apply to the pods
    extraEnv: []

    # lsp autoscaling configuration
    autoscaling:
      # -- enable or disable autoscaling
      enabled: false
      # -- maximum autoscaler replicas
      maxReplicas: 10
      # -- target CPU utilization
      targetCPUUtilizationPercentage: 80

  # multiplayer configuration
  multiplayer:
    tag: "latest"
    # -- Annotations to apply to the pods
    annotations: {}

    # -- Node selector to use for scheduling the pods
    nodeSelector: {}

    # -- Tolerations to apply to the pods
    tolerations: []

    # -- Affinity rules to apply to the pods
    affinity: {}

    # -- Resource limits and requests for the pods
    resources: {}

    # -- Extra environment variables to apply to the pods
    extraEnv: []

    # lsp autoscaling configuration
    autoscaling:
      # -- enable or disable autoscaling
      enabled: false
      # -- maximum autoscaler replicas
      maxReplicas: 10
      # -- target CPU utilization
      targetCPUUtilizationPercentage: 80

ingress:
  # -- enable/disable included ingress resource
  enabled: true
  className: ""
  annotations: {}
  # -- TLS config for the ingress resource. Useful when using cert-manager and nginx-ingress
  tls: []

enterprise:
  # -- enable Windmill Enterprise , requires license key.
  enabled: false
  enabledS3DistributedCache: false
  # -- S3 bucket to use for dependency cache. Sets S3_CACHE_BUCKET environment variable in worker container
  s3CacheBucket: mybucketname
  # -- Windmill provided Enterprise license key. Sets LICENSE_KEY environment variable in app and worker container.
  licenseKey: 123456F
  # -- use nsjail for sandboxing
  nsjail: false

serviceAccount:
  # Specifies whether a ServiceAccount should be created
  create: true
  # The name of the ServiceAccount to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""
  annotations: {}